{
    "sourceFile": "src/services/downlaod_manager/download_manager.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 48,
            "patches": [
                {
                    "date": 1744751360376,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1744751454804,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,9 +1,9 @@\n from cookies_authentication import (\n     create_cookies_from_browser_cookies,\n     save_cookies_to_file,\n )\n-from message_hub import MessageHub\n+from src.services.message_HUB.message_hub import MessageHub\n import asyncio\n import os\n \n \n"
                },
                {
                    "date": 1744751930510,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -75,4 +75,23 @@\n         error_message = f\"Error processing task: {str(e)}\"\n         print(error_message)\n         message_hub.send_message(status_topic, key=name, value={\"status\": error_message})\n \n+\n+\n+\n+if __name__ == \"__main__\":\n+    # Kafka configuration\n+    kafka_config =config_const.KAFKA_CONFIG\n+    kafka_topic = config_const.KAFKA_TOPIC_DOWNLOAD_REQUESTS\n+    status_topic = config_const.KAFKA_TOPIC_DOWNLOAD_STATUS\n+\n+    # Initialize the Message Hub\n+    message_hub = MessageHub(kafka_config)\n+\n+    # Consume tasks from Kafka\n+    def handle_task(task):\n+        asyncio.run(MessageHub.process_task(task, message_hub, status_topic))\n+\n+    message_hub.consume_messages(\n+        kafka_topic, group_id=\"download-manager-group\", callback=handle_task\n+    )\n\\ No newline at end of file\n"
                },
                {
                    "date": 1744751967954,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,8 +1,11 @@\n from cookies_authentication import (\n     create_cookies_from_browser_cookies,\n     save_cookies_to_file,\n )\n+\n+from src.const.config_const import KAFKA_CONFIG, KAFKA_TOPIC_DOWNLOAD_STATUS,   KAFKA_TOPIC_DOWNLOAD_REQUESTS\n+\n from src.services.message_HUB.message_hub import MessageHub\n import asyncio\n import os\n \n"
                },
                {
                    "date": 1744751979416,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,9 +2,10 @@\n     create_cookies_from_browser_cookies,\n     save_cookies_to_file,\n )\n \n-from src.const.config_const import KAFKA_CONFIG, KAFKA_TOPIC_DOWNLOAD_STATUS,   KAFKA_TOPIC_DOWNLOAD_REQUESTS\n+from src.const.config_const import KAFKA_CONFIG, KAFKA_TOPIC_DOWNLOAD_STATUS,\\\n+    KAFKA_TOPIC_DOWNLOAD_REQUESTS\n \n from src.services.message_HUB.message_hub import MessageHub\n import asyncio\n import os\n"
                },
                {
                    "date": 1744751990612,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,10 +2,10 @@\n     create_cookies_from_browser_cookies,\n     save_cookies_to_file,\n )\n \n-from src.const.config_const import KAFKA_CONFIG, KAFKA_TOPIC_DOWNLOAD_STATUS,\\\n-    KAFKA_TOPIC_DOWNLOAD_REQUESTS\n+from src.const.config_const import KAFKA_CONFIG,\\\n+     KAFKA_TOPIC_DOWNLOAD_STATUS , KAFKA_TOPIC_DOWNLOAD_REQUESTS\n \n from src.services.message_HUB.message_hub import MessageHub\n import asyncio\n import os\n"
                },
                {
                    "date": 1744751998294,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -84,11 +84,11 @@\n \n \n if __name__ == \"__main__\":\n     # Kafka configuration\n-    kafka_config =config_const.KAFKA_CONFIG\n-    kafka_topic = config_const.KAFKA_TOPIC_DOWNLOAD_REQUESTS\n-    status_topic = config_const.KAFKA_TOPIC_DOWNLOAD_STATUS\n+    kafka_config =KAFKA_CONFIG\n+    kafka_topic = KAFKA_TOPIC_DOWNLOAD_REQUESTS\n+    status_topic = KAFKA_TOPIC_DOWNLOAD_STATUS\n \n     # Initialize the Message Hub\n     message_hub = MessageHub(kafka_config)\n \n"
                },
                {
                    "date": 1744753183700,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,101 +1,79 @@\n+import os\n+import asyncio\n from cookies_authentication import (\n     create_cookies_from_browser_cookies,\n     save_cookies_to_file,\n )\n-\n-from src.const.config_const import KAFKA_CONFIG,\\\n-     KAFKA_TOPIC_DOWNLOAD_STATUS , KAFKA_TOPIC_DOWNLOAD_REQUESTS\n-\n+from src.const.config_const import (\n+    KAFKA_CONFIG,\n+    KAFKA_TOPIC_DOWNLOAD_STATUS,\n+    KAFKA_TOPIC_DOWNLOAD_REQUESTS,\n+)\n from src.services.message_HUB.message_hub import MessageHub\n-import asyncio\n-import os\n \n \n-async def download_video(cookies_path, link, name, folder_path):\n-    \"\"\"\n-    Asynchronously download a video using yt-dlp.\n-    \"\"\"\n-    os.makedirs(folder_path, exist_ok=True)\n-    output_path = os.path.join(folder_path, f\"{name}.%(ext)s\")\n-    if cookies_path is None:\n-        command = [\n-            \"yt-dlp\",\n-            link,\n-            \"-o\",\n-            os.path.abspath(output_path),\n-        ]\n-    else:\n-        command = [\n-            \"yt-dlp\",\n-            \"--cookies\",\n-            os.path.abspath(cookies_path),\n-            link,\n-            \"-o\",\n-            os.path.abspath(output_path),\n-        ]\n+class DownloadManager:\n+    def __init__(self, kafka_config=None, request_topic=None, status_topic=None):\n+        self._kafka_config = kafka_config or KAFKA_CONFIG\n+        self._request_topic = request_topic or KAFKA_TOPIC_DOWNLOAD_REQUESTS\n+        self._status_topic = status_topic or KAFKA_TOPIC_DOWNLOAD_STATUS\n+        self.message_hub = MessageHub(self._kafka_config)\n \n-    process = await asyncio.create_subprocess_exec(\n-        *command,\n-        stdout=asyncio.subprocess.PIPE,        stderr=asyncio.subprocess.PIPE,\n-    )\n-    stdout, stderr = await process.communicate()\n+    async def _download_video(self, cookies_path, link, name, folder_path):\n+        os.makedirs(folder_path, exist_ok=True)\n+        output_path = os.path.join(folder_path, f\"{name}.%(ext)s\")\n+        command = [\"yt-dlp\"]\n+        if cookies_path:\n+            command += [\"--cookies\", os.path.abspath(cookies_path)]\n+        command += [link, \"-o\", os.path.abspath(output_path)]\n \n-    if process.returncode == 0:\n-        return f\"SUCCESS: {link} downloaded to {folder_path} as {name}\"\n-    else:\n-        return f\"FAILED: {link} - {stderr.decode().strip()}\"\n+        process = await asyncio.create_subprocess_exec(\n+            *command,\n+            stdout=asyncio.subprocess.PIPE,\n+            stderr=asyncio.subprocess.PIPE,\n+        )\n+        stdout, stderr = await process.communicate()\n \n+        if process.returncode == 0:\n+            return f\"SUCCESS: {link} downloaded to {folder_path} as {name}\"\n+        else:\n+            return f\"FAILED: {link} - {stderr.decode().strip()}\"\n \n-async def process_task(task,  message_hub, status_topic):\n-    \"\"\"\n-    Processes a single download task.\n-    \"\"\"\n-    try:\n-        link = task[\"link\"]\n-        name = task[\"name\"]\n-        try: \n-            need_cookies = task[\"need_authentication\"] \n-        except KeyError:\n-            need_cookies = False\n+    async def _process_task(self, task):\n+        try:\n+            link = task[\"link\"]\n+            name = task[\"name\"]\n+            need_cookies = task.get(\"need_authentication\", False)\n             cookies_path = None\n-            \n-        \n-        cookies_path = None\n-        folder_name = task[\"folder_name\"]\n-        folder_path = os.path.join(\"./resources\", folder_name)\n-        if eval(need_cookies):\n\\ No newline at end of file\n-            raw_cookie_path = task[\"raw_cookies_path\"]\n-            cookies_path =  task[\"cookies_path\"]\n-            cookies = create_cookies_from_browser_cookies(raw_cookie_path)\n-            save_cookies_to_file(cookies_path, cookies)   \n-            \n \n-        # Execute the download\n-        status = await download_video(cookies_path, link, name, folder_path)\n+            folder_name = task[\"folder_name\"]\n+            folder_path = os.path.join(\"./resources\", folder_name)\n \n-        # Publish the status to the status topic\n-        message_hub.send_message(status_topic, key=name, value={\"status\": status})\n-    except Exception as e:\n-        error_message = f\"Error processing task: {str(e)}\"\n-        print(error_message)\n-        message_hub.send_message(status_topic, key=name, value={\"status\": error_message})\n+            if eval(str(need_cookies)):\n+                raw_cookie_path = task[\"raw_cookies_path\"]\n+                cookies_path = task[\"cookies_path\"]\n+                cookies = create_cookies_from_browser_cookies(raw_cookie_path)\n+                save_cookies_to_file(cookies_path, cookies)\n \n+            status = await self._download_video(cookies_path, link, name, folder_path)\n+            self.message_hub.send_message(self._status_topic, key=name, value={\"status\": status})\n \n+        except Exception as e:\n+            error_message = f\"Error processing task: {str(e)}\"\n+            print(error_message)\n+            self.message_hub.send_message(self._status_topic, key=task.get(\"name\", \"unknown\"), value={\"status\": error_message})\n \n+    def run(self):\n+        def handle_task(task):\n+            asyncio.run(self._process_task(task))\n \n-if __name__ == \"__main__\":\n-    # Kafka configuration\n-    kafka_config =KAFKA_CONFIG\n-    kafka_topic = KAFKA_TOPIC_DOWNLOAD_REQUESTS\n-    status_topic = KAFKA_TOPIC_DOWNLOAD_STATUS\n+        self.message_hub.consume_messages(\n+            self._request_topic,\n+            group_id=\"download-manager-group\",\n+            callback=handle_task,\n+        )\n \n-    # Initialize the Message Hub\n-    message_hub = MessageHub(kafka_config)\n \n-    # Consume tasks from Kafka\n-    def handle_task(task):\n-        asyncio.run(MessageHub.process_task(task, message_hub, status_topic))\n-\n-    message_hub.consume_messages(\n-        kafka_topic, group_id=\"download-manager-group\", callback=handle_task\n-    )\n+if __name__ == \"__main__\":\n+    manager = DownloadManager()\n+    manager.run()\n"
                },
                {
                    "date": 1744753282835,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,7 +1,7 @@\n import os\n import asyncio\n-from cookies_authentication import (\n+from src.services.downlaod_manager.cookies_authentication import (\n     create_cookies_from_browser_cookies,\n     save_cookies_to_file,\n )\n from src.const.config_const import (\n"
                },
                {
                    "date": 1744753882085,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -48,9 +48,9 @@\n \n             folder_name = task[\"folder_name\"]\n             folder_path = os.path.join(\"./resources\", folder_name)\n \n-            if eval(str(need_cookies)):\n+            if str(need_cookies).lower() == 'true':\n                 raw_cookie_path = task[\"raw_cookies_path\"]\n                 cookies_path = task[\"cookies_path\"]\n                 cookies = create_cookies_from_browser_cookies(raw_cookie_path)\n                 save_cookies_to_file(cookies_path, cookies)\n"
                },
                {
                    "date": 1744756954842,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,6 +1,7 @@\n import os\n import asyncio\n+from collections import defaultdict\n from src.services.downlaod_manager.cookies_authentication import (\n     create_cookies_from_browser_cookies,\n     save_cookies_to_file,\n )\n@@ -13,12 +14,19 @@\n \n \n class DownloadManager:\n     def __init__(self, kafka_config=None, request_topic=None, status_topic=None):\n+        # ...existing init code...\n         self._kafka_config = kafka_config or KAFKA_CONFIG\n         self._request_topic = request_topic or KAFKA_TOPIC_DOWNLOAD_REQUESTS\n         self._status_topic = status_topic or KAFKA_TOPIC_DOWNLOAD_STATUS\n         self.message_hub = MessageHub(self._kafka_config)\n+        \n+        # Add concurrent download management\n+        self.max_concurrent = config_const.MAX_CONCURRENT_DOWNLOADS\n+        self.active_downloads = defaultdict(int)\n+        self.folder_semaphores = {}\n+        self.global_semaphore = asyncio.Semaphore(self.max_concurrent)\n \n     async def _download_video(self, cookies_path, link, name, folder_path):\n         os.makedirs(folder_path, exist_ok=True)\n         output_path = os.path.join(folder_path, f\"{name}.%(ext)s\")\n"
                },
                {
                    "date": 1744756967480,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -8,8 +8,9 @@\n from src.const.config_const import (\n     KAFKA_CONFIG,\n     KAFKA_TOPIC_DOWNLOAD_STATUS,\n     KAFKA_TOPIC_DOWNLOAD_REQUESTS,\n+    MAX_CONCURRENT_DOWNLOADS\n )\n from src.services.message_HUB.message_hub import MessageHub\n \n \n@@ -21,9 +22,9 @@\n         self._status_topic = status_topic or KAFKA_TOPIC_DOWNLOAD_STATUS\n         self.message_hub = MessageHub(self._kafka_config)\n         \n         # Add concurrent download management\n-        self.max_concurrent = config_const.MAX_CONCURRENT_DOWNLOADS\n+        self.max_concurrent = MAX_CONCURRENT_DOWNLOADS\n         self.active_downloads = defaultdict(int)\n         self.folder_semaphores = {}\n         self.global_semaphore = asyncio.Semaphore(self.max_concurrent)\n \n"
                },
                {
                    "date": 1744756975886,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -9,8 +9,9 @@\n     KAFKA_CONFIG,\n     KAFKA_TOPIC_DOWNLOAD_STATUS,\n     KAFKA_TOPIC_DOWNLOAD_REQUESTS,\n     MAX_CONCURRENT_DOWNLOADS\n+    \n )\n from src.services.message_HUB.message_hub import MessageHub\n \n \n"
                },
                {
                    "date": 1744757052148,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -48,31 +48,81 @@\n             return f\"SUCCESS: {link} downloaded to {folder_path} as {name}\"\n         else:\n             return f\"FAILED: {link} - {stderr.decode().strip()}\"\n \n+    # async def _process_task(self, task):\n+    #     try:\n+    #         link = task[\"link\"]\n+    #         name = task[\"name\"]\n+    #         need_cookies = task.get(\"need_authentication\", False)\n+    #         cookies_path = None\n+\n+    #         folder_name = task[\"folder_name\"]\n+    #         folder_path = os.path.join(\"./resources\", folder_name)\n+\n+    #         if str(need_cookies).lower() == 'true':\n+    #             raw_cookie_path = task[\"raw_cookies_path\"]\n+    #             cookies_path = task[\"cookies_path\"]\n+    #             cookies = create_cookies_from_browser_cookies(raw_cookie_path)\n+    #             save_cookies_to_file(cookies_path, cookies)\n+\n+    #         status = await self._download_video(cookies_path, link, name, folder_path)\n+    #         self.message_hub.send_message(self._status_topic, key=name, value={\"status\": status})\n+\n+    #     except Exception as e:\n+    #         error_message = f\"Error processing task: {str(e)}\"\n+    #         print(error_message)\n+    #         self.message_hub.send_message(self._status_topic, key=task.get(\"name\", \"unknown\"), value={\"status\": error_message})\n+\n+    # def run(self):\n+    #     def handle_task(task):\n+    #         asyncio.run(self._process_task(task))\n+\n+    #     self.message_hub.consume_messages(\n+    #         self._request_topic,\n+    #         group_id=\"download-manager-group\",\n+    #         callback=handle_task,\n+    #     )\n+\n     async def _process_task(self, task):\n+        folder_name = task[\"folder_name\"]\n+        max_concurrent = task.get(\"max_concurrent\", config_const.MAX_CONCURRENT_DOWNLOADS_PER_FOLDER)\n+        \n+        # Create folder semaphore if it doesn't exist\n+        if folder_name not in self.folder_semaphores:\n+            self.folder_semaphores[folder_name] = asyncio.Semaphore(max_concurrent)\n+\n         try:\n-            link = task[\"link\"]\n-            name = task[\"name\"]\n-            need_cookies = task.get(\"need_authentication\", False)\n-            cookies_path = None\n+            # Use both semaphores for concurrent control\n+            async with self.global_semaphore, self.folder_semaphores[folder_name]:\n+                self.active_downloads[folder_name] += 1\n+                \n+                # Extract existing task parameters\n+                link = task[\"link\"]\n+                name = task[\"name\"]\n+                need_cookies = task.get(\"need_authentication\", False)\n+                cookies_path = None\n+                folder_path = os.path.join(\"./resources\", folder_name)\n \n-            folder_name = task[\"folder_name\"]\n-            folder_path = os.path.join(\"./resources\", folder_name)\n+                if str(need_cookies).lower() == 'true':\n+                    raw_cookie_path = task[\"raw_cookies_path\"]\n+                    cookies_path = task[\"cookies_path\"]\n+                    cookies = create_cookies_from_browser_cookies(raw_cookie_path)\n+                    save_cookies_to_file(cookies_path, cookies)\n \n-            if str(need_cookies).lower() == 'true':\n-                raw_cookie_path = task[\"raw_cookies_path\"]\n-                cookies_path = task[\"cookies_path\"]\n-                cookies = create_cookies_from_browser_cookies(raw_cookie_path)\n-                save_cookies_to_file(cookies_path, cookies)\n+                status = await self._download_video(cookies_path, link, name, folder_path)\n+                self.message_hub.send_message(self._status_topic, key=name, value={\"status\": status})\n \n-            status = await self._download_video(cookies_path, link, name, folder_path)\n-            self.message_hub.send_message(self._status_topic, key=name, value={\"status\": status})\n-\n         except Exception as e:\n             error_message = f\"Error processing task: {str(e)}\"\n             print(error_message)\n-            self.message_hub.send_message(self._status_topic, key=task.get(\"name\", \"unknown\"), value={\"status\": error_message})\n+            self.message_hub.send_message(\n+                self._status_topic, \n+                key=task.get(\"name\", \"unknown\"), \n+                value={\"status\": error_message}\n+            )\n+        finally:\n+            self.active_downloads[folder_name] -= 1\n \n     def run(self):\n         def handle_task(task):\n             asyncio.run(self._process_task(task))\n"
                },
                {
                    "date": 1744757241636,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -84,9 +84,9 @@\n     #     )\n \n     async def _process_task(self, task):\n         folder_name = task[\"folder_name\"]\n-        max_concurrent = task.get(\"max_concurrent\", config_const.MAX_CONCURRENT_DOWNLOADS_PER_FOLDER)\n+        max_concurrent = task.get(\"max_concurrent\", MAX_CONCURRENT_DOWNLOADS_PER_FOLDER)\n         \n         # Create folder semaphore if it doesn't exist\n         if folder_name not in self.folder_semaphores:\n             self.folder_semaphores[folder_name] = asyncio.Semaphore(max_concurrent)\n"
                },
                {
                    "date": 1744757251688,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -8,9 +8,9 @@\n from src.const.config_const import (\n     KAFKA_CONFIG,\n     KAFKA_TOPIC_DOWNLOAD_STATUS,\n     KAFKA_TOPIC_DOWNLOAD_REQUESTS,\n-    MAX_CONCURRENT_DOWNLOADS\n+    MAX_CONCURRENT_DOWNLOADS,MAX_CONCURRENT_DOWNLOADS_PER_FOLDER\n     \n )\n from src.services.message_HUB.message_hub import MessageHub\n \n"
                },
                {
                    "date": 1744757377976,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -122,8 +122,17 @@\n             )\n         finally:\n             self.active_downloads[folder_name] -= 1\n \n+\n+            \n+    async def process_messages(self, messages):\n+        tasks = []\n+        for message in messages:\n+            tasks.append(self._process_task(message))\n+        await asyncio.gather(*tasks)\n+\n+\n     def run(self):\n         def handle_task(task):\n             asyncio.run(self._process_task(task))\n \n"
                },
                {
                    "date": 1744757399900,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -132,17 +132,25 @@\n         await asyncio.gather(*tasks)\n \n \n     def run(self):\n-        def handle_task(task):\n-            asyncio.run(self._process_task(task))\n+        async def message_handler():\n+            messages = []\n+            async for message in self.message_hub.consume_messages_async(\n+                self._request_topic,\n+                group_id=\"download-manager-group\"\n+            ):\n+                messages.append(message)\n+                if len(messages) >= self.max_concurrent:\n+                    await self.process_messages(messages)\n+                    messages = []\n+            \n+            # Process any remaining messages\n+            if messages:\n+                await self.process_messages(messages)\n \n-        self.message_hub.consume_messages(\n-            self._request_topic,\n-            group_id=\"download-manager-group\",\n-            callback=handle_task,\n-        )\n+        # Run the async event loop\n+        asyncio.run(message_handler())\n \n-\n if __name__ == \"__main__\":\n     manager = DownloadManager()\n     manager.run()\n"
                },
                {
                    "date": 1744761051995,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -48,42 +48,10 @@\n             return f\"SUCCESS: {link} downloaded to {folder_path} as {name}\"\n         else:\n             return f\"FAILED: {link} - {stderr.decode().strip()}\"\n \n-    # async def _process_task(self, task):\n-    #     try:\n-    #         link = task[\"link\"]\n-    #         name = task[\"name\"]\n-    #         need_cookies = task.get(\"need_authentication\", False)\n-    #         cookies_path = None\n+     \n \n-    #         folder_name = task[\"folder_name\"]\n-    #         folder_path = os.path.join(\"./resources\", folder_name)\n-\n-    #         if str(need_cookies).lower() == 'true':\n-    #             raw_cookie_path = task[\"raw_cookies_path\"]\n-    #             cookies_path = task[\"cookies_path\"]\n-    #             cookies = create_cookies_from_browser_cookies(raw_cookie_path)\n-    #             save_cookies_to_file(cookies_path, cookies)\n-\n-    #         status = await self._download_video(cookies_path, link, name, folder_path)\n-    #         self.message_hub.send_message(self._status_topic, key=name, value={\"status\": status})\n-\n-    #     except Exception as e:\n-    #         error_message = f\"Error processing task: {str(e)}\"\n-    #         print(error_message)\n-    #         self.message_hub.send_message(self._status_topic, key=task.get(\"name\", \"unknown\"), value={\"status\": error_message})\n-\n-    # def run(self):\n-    #     def handle_task(task):\n-    #         asyncio.run(self._process_task(task))\n-\n-    #     self.message_hub.consume_messages(\n-    #         self._request_topic,\n-    #         group_id=\"download-manager-group\",\n-    #         callback=handle_task,\n-    #     )\n-\n     async def _process_task(self, task):\n         folder_name = task[\"folder_name\"]\n         max_concurrent = task.get(\"max_concurrent\", MAX_CONCURRENT_DOWNLOADS_PER_FOLDER)\n         \n"
                },
                {
                    "date": 1744761102027,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -16,9 +16,9 @@\n \n \n class DownloadManager:\n     def __init__(self, kafka_config=None, request_topic=None, status_topic=None):\n-        # ...existing init code...\n+        \n         self._kafka_config = kafka_config or KAFKA_CONFIG\n         self._request_topic = request_topic or KAFKA_TOPIC_DOWNLOAD_REQUESTS\n         self._status_topic = status_topic or KAFKA_TOPIC_DOWNLOAD_STATUS\n         self.message_hub = MessageHub(self._kafka_config)\n"
                },
                {
                    "date": 1744761267786,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -27,9 +27,11 @@\n         self.max_concurrent = MAX_CONCURRENT_DOWNLOADS\n         self.active_downloads = defaultdict(int)\n         self.folder_semaphores = {}\n         self.global_semaphore = asyncio.Semaphore(self.max_concurrent)\n+        self.lock = asyncio.Lock()  # Add lock for thread-safe counting\n \n+\n     async def _download_video(self, cookies_path, link, name, folder_path):\n         os.makedirs(folder_path, exist_ok=True)\n         output_path = os.path.join(folder_path, f\"{name}.%(ext)s\")\n         command = [\"yt-dlp\"]\n"
                },
                {
                    "date": 1744761333191,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -54,32 +54,33 @@\n      \n \n     async def _process_task(self, task):\n         folder_name = task[\"folder_name\"]\n-        max_concurrent = task.get(\"max_concurrent\", MAX_CONCURRENT_DOWNLOADS_PER_FOLDER)\n+        max_concurrent = min(\n+            task.get(\"max_concurrent\", MAX_CONCURRENT_DOWNLOADS_PER_FOLDER),\n+            self.max_concurrent\n+        )\n         \n         # Create folder semaphore if it doesn't exist\n         if folder_name not in self.folder_semaphores:\n             self.folder_semaphores[folder_name] = asyncio.Semaphore(max_concurrent)\n \n         try:\n+            # First check if we can start a new download\n+            async with self.lock:\n+                if (self.total_active_downloads >= self.max_concurrent or \n+                    self.active_downloads[folder_name] >= max_concurrent):\n+                    return  # Skip this task if we're at the limit\n+                \n+                self.active_downloads[folder_name] += 1\n+                self.total_active_downloads += 1\n+                print(f\"Active downloads in {folder_name}: {self.active_downloads[folder_name]}\")\n+                print(f\"Total active downloads: {self.total_active_downloads}\")\n+\n             # Use both semaphores for concurrent control\n             async with self.global_semaphore, self.folder_semaphores[folder_name]:\n-                self.active_downloads[folder_name] += 1\n-                \n-                # Extract existing task parameters\n-                link = task[\"link\"]\n-                name = task[\"name\"]\n-                need_cookies = task.get(\"need_authentication\", False)\n-                cookies_path = None\n-                folder_path = os.path.join(\"./resources\", folder_name)\n-\n-                if str(need_cookies).lower() == 'true':\n-                    raw_cookie_path = task[\"raw_cookies_path\"]\n-                    cookies_path = task[\"cookies_path\"]\n-                    cookies = create_cookies_from_browser_cookies(raw_cookie_path)\n-                    save_cookies_to_file(cookies_path, cookies)\n-\n+                # Extract existing task parameters and process download\n+                # ...existing download code...\n                 status = await self._download_video(cookies_path, link, name, folder_path)\n                 self.message_hub.send_message(self._status_topic, key=name, value={\"status\": status})\n \n         except Exception as e:\n@@ -90,19 +91,27 @@\n                 key=task.get(\"name\", \"unknown\"), \n                 value={\"status\": error_message}\n             )\n         finally:\n-            self.active_downloads[folder_name] -= 1\n+            async with self.lock:\n+                self.active_downloads[folder_name] -= 1\n+                self.total_active_downloads -= 1\n+                print(f\"Completed download in {folder_name}. Active: {self.active_downloads[folder_name]}\")\n+                print(f\"Total active downloads: {self.total_active_downloads}\")\n \n \n+\n             \n     async def process_messages(self, messages):\n         tasks = []\n         for message in messages:\n-            tasks.append(self._process_task(message))\n-        await asyncio.gather(*tasks)\n-\n-\n+            if self.total_active_downloads < self.max_concurrent:\n+                tasks.append(self._process_task(message))\n+            else:\n+                # Wait for some downloads to complete\n+                await asyncio.sleep(1)\n+        if tasks:\n+            await asyncio.gather(*tasks)\n     def run(self):\n         async def message_handler():\n             messages = []\n             async for message in self.message_hub.consume_messages_async(\n"
                },
                {
                    "date": 1744761492001,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,10 +1,9 @@\n import os\n import asyncio\n from collections import defaultdict\n from src.services.downlaod_manager.cookies_authentication import (\n-    create_cookies_from_browser_cookies,\n-    save_cookies_to_file,\n+    \n )\n from src.const.config_const import (\n     KAFKA_CONFIG,\n     KAFKA_TOPIC_DOWNLOAD_STATUS,\n@@ -110,8 +109,10 @@\n                 # Wait for some downloads to complete\n                 await asyncio.sleep(1)\n         if tasks:\n             await asyncio.gather(*tasks)\n+\n+            \n     def run(self):\n         async def message_handler():\n             messages = []\n             async for message in self.message_hub.consume_messages_async(\n"
                },
                {
                    "date": 1744761503627,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,10 +1,7 @@\n import os\n import asyncio\n from collections import defaultdict\n-from src.services.downlaod_manager.cookies_authentication import (\n-    \n-)\n from src.const.config_const import (\n     KAFKA_CONFIG,\n     KAFKA_TOPIC_DOWNLOAD_STATUS,\n     KAFKA_TOPIC_DOWNLOAD_REQUESTS,\n"
                },
                {
                    "date": 1744761515751,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -21,8 +21,9 @@\n         \n         # Add concurrent download management\n         self.max_concurrent = MAX_CONCURRENT_DOWNLOADS\n         self.active_downloads = defaultdict(int)\n+        self.total_active_downloads = 0  # Add this line to initialize the counter\n         self.folder_semaphores = {}\n         self.global_semaphore = asyncio.Semaphore(self.max_concurrent)\n         self.lock = asyncio.Lock()  # Add lock for thread-safe counting\n \n"
                },
                {
                    "date": 1744761621160,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -4,9 +4,10 @@\n from src.const.config_const import (\n     KAFKA_CONFIG,\n     KAFKA_TOPIC_DOWNLOAD_STATUS,\n     KAFKA_TOPIC_DOWNLOAD_REQUESTS,\n-    MAX_CONCURRENT_DOWNLOADS,MAX_CONCURRENT_DOWNLOADS_PER_FOLDER\n+    MAX_CONCURRENT_DOWNLOADS,\n+    MAX_CONCURRENT_DOWNLOADS_PER_FOLDER\n     \n )\n from src.services.message_HUB.message_hub import MessageHub\n \n"
                },
                {
                    "date": 1744761857202,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -5,10 +5,9 @@\n     KAFKA_CONFIG,\n     KAFKA_TOPIC_DOWNLOAD_STATUS,\n     KAFKA_TOPIC_DOWNLOAD_REQUESTS,\n     MAX_CONCURRENT_DOWNLOADS,\n-    MAX_CONCURRENT_DOWNLOADS_PER_FOLDER\n-    \n+    MAX_CONCURRENT_DOWNLOADS_PER_FOLDER    \n )\n from src.services.message_HUB.message_hub import MessageHub\n \n \n@@ -77,8 +76,14 @@\n             # Use both semaphores for concurrent control\n             async with self.global_semaphore, self.folder_semaphores[folder_name]:\n                 # Extract existing task parameters and process download\n                 # ...existing download code...\n+                link = task[\"link\"]\n+                name = task[\"name\"]\n+                folder_path = os.path.join(\"./resources\", folder_name)\n+                cookies_path = task.get(\"cookies_path\") if task.get(\"need_authentication\") else None\n+\n+                \n                 status = await self._download_video(cookies_path, link, name, folder_path)\n                 self.message_hub.send_message(self._status_topic, key=name, value={\"status\": status})\n \n         except Exception as e:\n"
                },
                {
                    "date": 1744762440012,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -103,18 +103,28 @@\n \n \n \n             \n-    async def process_messages(self, messages):\n-        tasks = []\n-        for message in messages:\n-            if self.total_active_downloads < self.max_concurrent:\n+async def process_messages(self, messages):\n+    # Create a list to hold all tasks\n+    tasks = []\n+    async with self.lock:\n+        available_slots = self.max_concurrent - self.total_active_downloads\n+        if available_slots > 0:\n+            # Take only as many messages as we can process\n+            messages_to_process = messages[:available_slots]\n+            print(f\"Processing {len(messages_to_process)} messages out of {len(messages)} available\")\n+            \n+            for message in messages_to_process:\n                 tasks.append(self._process_task(message))\n-            else:\n-                # Wait for some downloads to complete\n-                await asyncio.sleep(1)\n-        if tasks:\n-            await asyncio.gather(*tasks)\n+    \n+    if tasks:\n+        # Run tasks concurrently\n+        await asyncio.gather(*tasks)\n+    else:\n+        # If no slots available, wait briefly before next attempt\n+        print(\"No slots available for downloads, waiting...\")\n+        await asyncio.sleep(1)\n \n             \n     def run(self):\n         async def message_handler():\n"
                },
                {
                    "date": 1744762463271,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -124,27 +124,26 @@\n         # If no slots available, wait briefly before next attempt\n         print(\"No slots available for downloads, waiting...\")\n         await asyncio.sleep(1)\n \n-            \n-    def run(self):\n-        async def message_handler():\n-            messages = []\n-            async for message in self.message_hub.consume_messages_async(\n-                self._request_topic,\n-                group_id=\"download-manager-group\"\n-            ):\n-                messages.append(message)\n-                if len(messages) >= self.max_concurrent:\n-                    await self.process_messages(messages)\n-                    messages = []\n-            \n-            # Process any remaining messages\n-            if messages:\n+            async def run(self):\n+    async def message_handler():\n+        messages = []\n+        async for message in self.message_hub.consume_messages_async(\n+            self._request_topic,\n+            group_id=\"download-manager-group\"\n+        ):\n+            messages.append(message)\n+            # Process messages when we have enough or after a timeout\n+            if len(messages) >= self.max_concurrent:\n                 await self.process_messages(messages)\n+                messages = []\n+        \n+        # Process any remaining messages\n+        if messages:\n+            await self.process_messages(messages)\n \n-        # Run the async event loop\n-        asyncio.run(message_handler())\n-\n+    # Run the async event loop\n+    asyncio.run(message_handler())\n if __name__ == \"__main__\":\n     manager = DownloadManager()\n     manager.run()\n"
                },
                {
                    "date": 1744762550324,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -103,30 +103,21 @@\n \n \n \n             \n-async def process_messages(self, messages):\n-    # Create a list to hold all tasks\n-    tasks = []\n-    async with self.lock:\n-        available_slots = self.max_concurrent - self.total_active_downloads\n-        if available_slots > 0:\n-            # Take only as many messages as we can process\n-            messages_to_process = messages[:available_slots]\n-            print(f\"Processing {len(messages_to_process)} messages out of {len(messages)} available\")\n-            \n-            for message in messages_to_process:\n+    async def process_messages(self, messages):\n+        tasks = []\n+        for message in messages:\n+            if self.total_active_downloads < self.max_concurrent:\n                 tasks.append(self._process_task(message))\n-    \n-    if tasks:\n-        # Run tasks concurrently\n-        await asyncio.gather(*tasks)\n-    else:\n-        # If no slots available, wait briefly before next attempt\n-        print(\"No slots available for downloads, waiting...\")\n-        await asyncio.sleep(1)\n+            else:\n+                # Wait for some downloads to complete\n+                await asyncio.sleep(1)\n+        if tasks:\n+            await asyncio.gather(*tasks)\n \n-            async def run(self):\n+            \n+async def run(self):\n     async def message_handler():\n         messages = []\n         async for message in self.message_hub.consume_messages_async(\n             self._request_topic,\n@@ -143,7 +134,9 @@\n             await self.process_messages(messages)\n \n     # Run the async event loop\n     asyncio.run(message_handler())\n+\n+    \n if __name__ == \"__main__\":\n     manager = DownloadManager()\n     manager.run()\n"
                },
                {
                    "date": 1744762692789,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -115,27 +115,27 @@\n         if tasks:\n             await asyncio.gather(*tasks)\n \n             \n-async def run(self):\n-    async def message_handler():\n-        messages = []\n-        async for message in self.message_hub.consume_messages_async(\n-            self._request_topic,\n-            group_id=\"download-manager-group\"\n-        ):\n-            messages.append(message)\n-            # Process messages when we have enough or after a timeout\n-            if len(messages) >= self.max_concurrent:\n+    async def run(self):\n+        async def message_handler():\n+            messages = []\n+            async for message in self.message_hub.consume_messages_async(\n+                self._request_topic,\n+                group_id=\"download-manager-group\"\n+            ):\n+                messages.append(message)\n+                # Process messages when we have enough or after a timeout\n+                if len(messages) >= self.max_concurrent:\n+                    await self.process_messages(messages)\n+                    messages = []\n+            \n+            # Process any remaining messages\n+            if messages:\n                 await self.process_messages(messages)\n-                messages = []\n-        \n-        # Process any remaining messages\n-        if messages:\n-            await self.process_messages(messages)\n \n-    # Run the async event loop\n-    asyncio.run(message_handler())\n+        # Run the async event loop\n+        asyncio.run(message_handler())\n \n     \n if __name__ == \"__main__\":\n     manager = DownloadManager()\n"
                },
                {
                    "date": 1744762818933,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -138,5 +138,5 @@\n \n     \n if __name__ == \"__main__\":\n     manager = DownloadManager()\n-    manager.run()\n+    asyncio.run(manager.run())\n"
                },
                {
                    "date": 1744763293205,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -104,18 +104,27 @@\n \n \n             \n     async def process_messages(self, messages):\n+        # Create a list to hold all tasks\n         tasks = []\n-        for message in messages:\n-            if self.total_active_downloads < self.max_concurrent:\n-                tasks.append(self._process_task(message))\n-            else:\n-                # Wait for some downloads to complete\n-                await asyncio.sleep(1)\n+        async with self.lock:\n+            available_slots = self.max_concurrent - self.total_active_downloads\n+            if available_slots > 0:\n+                # Take only as many messages as we can process\n+                messages_to_process = messages[:available_slots]\n+                print(f\"Processing {len(messages_to_process)} messages out of {len(messages)} available\")\n+                \n+                for message in messages_to_process:\n+                    tasks.append(self._process_task(message))\n+        \n         if tasks:\n+            # Run tasks concurrently\n             await asyncio.gather(*tasks)\n-\n+        else:\n+            # If no slots available, wait briefly before next attempt\n+            print(\"No slots available for downloads, waiting...\")\n+            await asyncio.sleep(1)    \n             \n     async def run(self):\n         async def message_handler():\n             messages = []\n"
                },
                {
                    "date": 1744763462269,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -124,9 +124,9 @@\n             # If no slots available, wait briefly before next attempt\n             print(\"No slots available for downloads, waiting...\")\n             await asyncio.sleep(1)    \n             \n-    async def run(self):\n+    def run(self):\n         async def message_handler():\n             messages = []\n             async for message in self.message_hub.consume_messages_async(\n                 self._request_topic,\n@@ -147,5 +147,5 @@\n \n     \n if __name__ == \"__main__\":\n     manager = DownloadManager()\n-    asyncio.run(manager.run())\n+    manager.run()\n"
                },
                {
                    "date": 1744763678442,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -49,41 +49,91 @@\n             return f\"FAILED: {link} - {stderr.decode().strip()}\"\n \n      \n \n+    # async def _process_task(self, task):\n+    #     folder_name = task[\"folder_name\"]\n+    #     max_concurrent = min(\n+    #         task.get(\"max_concurrent\", MAX_CONCURRENT_DOWNLOADS_PER_FOLDER),\n+    #         self.max_concurrent\n+    #     )\n+        \n+    #     # Create folder semaphore if it doesn't exist\n+    #     if folder_name not in self.folder_semaphores:\n+    #         self.folder_semaphores[folder_name] = asyncio.Semaphore(max_concurrent)\n+\n+    #     try:\n+    #         # First check if we can start a new download\n+    #         async with self.lock:\n+    #             if (self.total_active_downloads >= self.max_concurrent or \n+    #                 self.active_downloads[folder_name] >= max_concurrent):\n+    #                 return  # Skip this task if we're at the limit\n+                \n+    #             self.active_downloads[folder_name] += 1\n+    #             self.total_active_downloads += 1\n+    #             print(f\"Active downloads in {folder_name}: {self.active_downloads[folder_name]}\")\n+    #             print(f\"Total active downloads: {self.total_active_downloads}\")\n+\n+    #         # Use both semaphores for concurrent control\n+    #         async with self.global_semaphore, self.folder_semaphores[folder_name]:\n+    #             # Extract existing task parameters and process download\n+    #             # ...existing download code...\n+    #             link = task[\"link\"]\n+    #             name = task[\"name\"]\n+    #             folder_path = os.path.join(\"./resources\", folder_name)\n+    #             cookies_path = task.get(\"cookies_path\") if task.get(\"need_authentication\") else None\n+\n+                \n+    #             status = await self._download_video(cookies_path, link, name, folder_path)\n+    #             self.message_hub.send_message(self._status_topic, key=name, value={\"status\": status})\n+\n+    #     except Exception as e:\n+    #         error_message = f\"Error processing task: {str(e)}\"\n+    #         print(error_message)\n+    #         self.message_hub.send_message(\n+    #             self._status_topic, \n+    #             key=task.get(\"name\", \"unknown\"), \n+    #             value={\"status\": error_message}\n+    #         )\n+    #     finally:\n+    #         async with self.lock:\n+    #             self.active_downloads[folder_name] -= 1\n+    #             self.total_active_downloads -= 1\n+    #             print(f\"Completed download in {folder_name}. Active: {self.active_downloads[folder_name]}\")\n+    #             print(f\"Total active downloads: {self.total_active_downloads}\")\n+\n     async def _process_task(self, task):\n         folder_name = task[\"folder_name\"]\n         max_concurrent = min(\n             task.get(\"max_concurrent\", MAX_CONCURRENT_DOWNLOADS_PER_FOLDER),\n             self.max_concurrent\n         )\n         \n-        # Create folder semaphore if it doesn't exist\n         if folder_name not in self.folder_semaphores:\n             self.folder_semaphores[folder_name] = asyncio.Semaphore(max_concurrent)\n \n         try:\n-            # First check if we can start a new download\n+            # Get lock before incrementing counters\n             async with self.lock:\n                 if (self.total_active_downloads >= self.max_concurrent or \n                     self.active_downloads[folder_name] >= max_concurrent):\n-                    return  # Skip this task if we're at the limit\n-                \n+                    print(f\"Skipping task - at limit. Total: {self.total_active_downloads}, Folder {folder_name}: {self.active_downloads[folder_name]}\")\n+                    return\n+\n                 self.active_downloads[folder_name] += 1\n                 self.total_active_downloads += 1\n-                print(f\"Active downloads in {folder_name}: {self.active_downloads[folder_name]}\")\n-                print(f\"Total active downloads: {self.total_active_downloads}\")\n+                current_folder_count = self.active_downloads[folder_name]\n+                current_total = self.total_active_downloads\n+                print(f\"Starting download in {folder_name}. Active: {current_folder_count}\")\n+                print(f\"Total active downloads: {current_total}\")\n \n-            # Use both semaphores for concurrent control\n+            # Process download\n             async with self.global_semaphore, self.folder_semaphores[folder_name]:\n-                # Extract existing task parameters and process download\n-                # ...existing download code...\n                 link = task[\"link\"]\n                 name = task[\"name\"]\n                 folder_path = os.path.join(\"./resources\", folder_name)\n                 cookies_path = task.get(\"cookies_path\") if task.get(\"need_authentication\") else None\n \n-                \n                 status = await self._download_video(cookies_path, link, name, folder_path)\n                 self.message_hub.send_message(self._status_topic, key=name, value={\"status\": status})\n \n         except Exception as e:\n@@ -94,16 +144,17 @@\n                 key=task.get(\"name\", \"unknown\"), \n                 value={\"status\": error_message}\n             )\n         finally:\n+            # Get lock before decrementing counters\n             async with self.lock:\n-                self.active_downloads[folder_name] -= 1\n-                self.total_active_downloads -= 1\n+                if self.active_downloads[folder_name] > 0:\n+                    self.active_downloads[folder_name] -= 1\n+                if self.total_active_downloads > 0:\n+                    self.total_active_downloads -= 1\n                 print(f\"Completed download in {folder_name}. Active: {self.active_downloads[folder_name]}\")\n                 print(f\"Total active downloads: {self.total_active_downloads}\")\n \n-\n-\n             \n     async def process_messages(self, messages):\n         # Create a list to hold all tasks\n         tasks = []\n"
                },
                {
                    "date": 1744764151603,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -25,8 +25,10 @@\n         self.total_active_downloads = 0  # Add this line to initialize the counter\n         self.folder_semaphores = {}\n         self.global_semaphore = asyncio.Semaphore(self.max_concurrent)\n         self.lock = asyncio.Lock()  # Add lock for thread-safe counting\n+        print(f\"Initializing Download Manager with max concurrent downloads: {self.max_concurrent}\")\n+        print(f\"Max concurrent downloads per folder: {MAX_CONCURRENT_DOWNLOADS_PER_FOLDER}\")\n \n \n     async def _download_video(self, cookies_path, link, name, folder_path):\n         os.makedirs(folder_path, exist_ok=True)\n"
                },
                {
                    "date": 1744764235857,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -177,28 +177,24 @@\n             # If no slots available, wait briefly before next attempt\n             print(\"No slots available for downloads, waiting...\")\n             await asyncio.sleep(1)    \n             \n-    def run(self):\n-        async def message_handler():\n-            messages = []\n-            async for message in self.message_hub.consume_messages_async(\n-                self._request_topic,\n-                group_id=\"download-manager-group\"\n-            ):\n-                messages.append(message)\n-                # Process messages when we have enough or after a timeout\n-                if len(messages) >= self.max_concurrent:\n-                    await self.process_messages(messages)\n-                    messages = []\n-            \n-            # Process any remaining messages\n-            if messages:\n+    async def run(self):\n+        print(\"Starting Download Manager...\")\n+        messages = []\n+        async for message in self.message_hub.consume_messages_async(\n+            self._request_topic,\n+            group_id=\"download-manager-group\"\n+        ):\n+            messages.append(message)\n+            # Process messages when we have enough or after a timeout\n+            if len(messages) >= self.max_concurrent:\n                 await self.process_messages(messages)\n+                messages = []\n+        \n+        # Process any remaining messages\n+        if messages:\n+            await self.process_messages(messages)\n \n-        # Run the async event loop\n-        asyncio.run(message_handler())\n-\n-    \n if __name__ == \"__main__\":\n     manager = DownloadManager()\n-    manager.run()\n+    asyncio.run(manager.run())\n\\ No newline at end of file\n"
                },
                {
                    "date": 1744764481882,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -178,23 +178,31 @@\n             print(\"No slots available for downloads, waiting...\")\n             await asyncio.sleep(1)    \n             \n     async def run(self):\n-        print(\"Starting Download Manager...\")\n-        messages = []\n-        async for message in self.message_hub.consume_messages_async(\n-            self._request_topic,\n-            group_id=\"download-manager-group\"\n-        ):\n-            messages.append(message)\n-            # Process messages when we have enough or after a timeout\n-            if len(messages) >= self.max_concurrent:\n-                await self.process_messages(messages)\n-                messages = []\n-        \n-        # Process any remaining messages\n-        if messages:\n-            await self.process_messages(messages)\n-\n+        logger.info(\"Download Manager run starting...\")\n+        try:\n+            messages = []\n+            logger.info(f\"Starting to consume messages from topic: {self._request_topic}\")\n+            \n+            message_count = 0\n+            async for message in self.message_hub.consume_messages_async(\n+                self._request_topic,\n+                group_id=\"download-manager-group\"\n+            ):\n+                message_count += 1\n+                logger.info(f\"Received message {message_count}: {message}\")\n+                \n+                messages.append(message)\n+                if len(messages) >= self.max_concurrent:\n+                    logger.info(f\"Processing batch of {len(messages)} messages\")\n+                    await self.process_messages(messages)\n+                    messages = []\n+                    \n+            logger.info(\"Message consumption completed\")\n+            \n+        except Exception as e:\n+            logger.error(f\"Error in run method: {str(e)}\", exc_info=True)\n+            raise\n if __name__ == \"__main__\":\n     manager = DownloadManager()\n     asyncio.run(manager.run())\n\\ No newline at end of file\n"
                },
                {
                    "date": 1744764495688,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,6 +1,7 @@\n import os\n import asyncio\n+import logging\n from collections import defaultdict\n from src.const.config_const import (\n     KAFKA_CONFIG,\n     KAFKA_TOPIC_DOWNLOAD_STATUS,\n@@ -202,7 +203,9 @@\n             \n         except Exception as e:\n             logger.error(f\"Error in run method: {str(e)}\", exc_info=True)\n             raise\n+\n+        \n if __name__ == \"__main__\":\n     manager = DownloadManager()\n     asyncio.run(manager.run())\n\\ No newline at end of file\n"
                },
                {
                    "date": 1744764570374,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -10,10 +10,15 @@\n     MAX_CONCURRENT_DOWNLOADS_PER_FOLDER    \n )\n from src.services.message_HUB.message_hub import MessageHub\n \n+logging.basicConfig(level=logging.INFO)\n+logger = logging.getLogger(__name__)\n \n class DownloadManager:\n+\n+\n+    \n     def __init__(self, kafka_config=None, request_topic=None, status_topic=None):\n         \n         self._kafka_config = kafka_config or KAFKA_CONFIG\n         self._request_topic = request_topic or KAFKA_TOPIC_DOWNLOAD_REQUESTS\n"
                },
                {
                    "date": 1744765487021,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -183,33 +183,34 @@\n             # If no slots available, wait briefly before next attempt\n             print(\"No slots available for downloads, waiting...\")\n             await asyncio.sleep(1)    \n             \n-    async def run(self):\n-        logger.info(\"Download Manager run starting...\")\n-        try:\n-            messages = []\n-            logger.info(f\"Starting to consume messages from topic: {self._request_topic}\")\n+async def run(self):\n+    logger.info(\"Download Manager run starting...\")\n+    try:\n+        messages = []\n+        logger.info(f\"Starting to consume messages from topic: {self._request_topic}\")\n+        \n+        message_count = 0\n+        async for message in self.message_hub.consume_messages_async(\n+            self._request_topic,\n+            group_id=\"download-manager-group\"\n+        ):\n+            message_count += 1\n+            logger.info(f\"Received message {message_count}: {message}\")\n             \n-            message_count = 0\n-            async for message in self.message_hub.consume_messages_async(\n-                self._request_topic,\n-                group_id=\"download-manager-group\"\n-            ):\n-                message_count += 1\n-                logger.info(f\"Received message {message_count}: {message}\")\n+            messages.append(message)\n+            # Process messages more frequently - when we have any messages\n+            if messages:\n+                logger.info(f\"Processing batch of {len(messages)} messages\")\n+                await self.process_messages(messages)\n+                messages = []\n                 \n-                messages.append(message)\n-                if len(messages) >= self.max_concurrent:\n-                    logger.info(f\"Processing batch of {len(messages)} messages\")\n-                    await self.process_messages(messages)\n-                    messages = []\n-                    \n-            logger.info(\"Message consumption completed\")\n-            \n-        except Exception as e:\n-            logger.error(f\"Error in run method: {str(e)}\", exc_info=True)\n-            raise\n+        logger.info(\"Message consumption completed\")\n+        \n+    except Exception as e:\n+        logger.error(f\"Error in run method: {str(e)}\", exc_info=True)\n+        raise\n \n         \n if __name__ == \"__main__\":\n     manager = DownloadManager()\n"
                },
                {
                    "date": 1744765511045,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -162,29 +162,27 @@\n                 print(f\"Completed download in {folder_name}. Active: {self.active_downloads[folder_name]}\")\n                 print(f\"Total active downloads: {self.total_active_downloads}\")\n \n             \n-    async def process_messages(self, messages):\n-        # Create a list to hold all tasks\n-        tasks = []\n-        async with self.lock:\n-            available_slots = self.max_concurrent - self.total_active_downloads\n-            if available_slots > 0:\n-                # Take only as many messages as we can process\n-                messages_to_process = messages[:available_slots]\n-                print(f\"Processing {len(messages_to_process)} messages out of {len(messages)} available\")\n-                \n-                for message in messages_to_process:\n-                    tasks.append(self._process_task(message))\n-        \n-        if tasks:\n-            # Run tasks concurrently\n-            await asyncio.gather(*tasks)\n-        else:\n-            # If no slots available, wait briefly before next attempt\n-            print(\"No slots available for downloads, waiting...\")\n-            await asyncio.sleep(1)    \n+async def process_messages(self, messages):\n+    tasks = []\n+    async with self.lock:\n+        available_slots = self.max_concurrent - self.total_active_downloads\n+        if available_slots > 0:\n+            messages_to_process = messages[:available_slots]\n+            logger.info(f\"Processing {len(messages_to_process)} messages out of {len(messages)} available\")\n             \n+            # Create coroutines for each task\n+            tasks = [self._process_task(message) for message in messages_to_process]\n+    \n+    if tasks:\n+        # Run tasks concurrently and wait for them to complete\n+        logger.info(f\"Starting {len(tasks)} download tasks\")\n+        await asyncio.gather(*tasks)\n+    else:\n+        logger.info(\"No slots available for downloads, waiting...\")\n+        await asyncio.sleep(1)  \n+            \n async def run(self):\n     logger.info(\"Download Manager run starting...\")\n     try:\n         messages = []\n"
                },
                {
                    "date": 1744765560904,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -55,61 +55,10 @@\n             return f\"SUCCESS: {link} downloaded to {folder_path} as {name}\"\n         else:\n             return f\"FAILED: {link} - {stderr.decode().strip()}\"\n \n-     \n+               print(f\"Total active downloads: {self.total_active_downloads}\")\n \n-    # async def _process_task(self, task):\n-    #     folder_name = task[\"folder_name\"]\n-    #     max_concurrent = min(\n-    #         task.get(\"max_concurrent\", MAX_CONCURRENT_DOWNLOADS_PER_FOLDER),\n-    #         self.max_concurrent\n-    #     )\n-        \n-    #     # Create folder semaphore if it doesn't exist\n-    #     if folder_name not in self.folder_semaphores:\n-    #         self.folder_semaphores[folder_name] = asyncio.Semaphore(max_concurrent)\n-\n-    #     try:\n-    #         # First check if we can start a new download\n-    #         async with self.lock:\n-    #             if (self.total_active_downloads >= self.max_concurrent or \n-    #                 self.active_downloads[folder_name] >= max_concurrent):\n-    #                 return  # Skip this task if we're at the limit\n-                \n-    #             self.active_downloads[folder_name] += 1\n-    #             self.total_active_downloads += 1\n-    #             print(f\"Active downloads in {folder_name}: {self.active_downloads[folder_name]}\")\n-    #             print(f\"Total active downloads: {self.total_active_downloads}\")\n-\n-    #         # Use both semaphores for concurrent control\n-    #         async with self.global_semaphore, self.folder_semaphores[folder_name]:\n-    #             # Extract existing task parameters and process download\n-    #             # ...existing download code...\n-    #             link = task[\"link\"]\n-    #             name = task[\"name\"]\n-    #             folder_path = os.path.join(\"./resources\", folder_name)\n-    #             cookies_path = task.get(\"cookies_path\") if task.get(\"need_authentication\") else None\n-\n-                \n-    #             status = await self._download_video(cookies_path, link, name, folder_path)\n-    #             self.message_hub.send_message(self._status_topic, key=name, value={\"status\": status})\n-\n-    #     except Exception as e:\n-    #         error_message = f\"Error processing task: {str(e)}\"\n-    #         print(error_message)\n-    #         self.message_hub.send_message(\n-    #             self._status_topic, \n-    #             key=task.get(\"name\", \"unknown\"), \n-    #             value={\"status\": error_message}\n-    #         )\n-    #     finally:\n-    #         async with self.lock:\n-    #             self.active_downloads[folder_name] -= 1\n-    #             self.total_active_downloads -= 1\n-    #             print(f\"Completed download in {folder_name}. Active: {self.active_downloads[folder_name]}\")\n-    #             print(f\"Total active downloads: {self.total_active_downloads}\")\n-\n     async def _process_task(self, task):\n         folder_name = task[\"folder_name\"]\n         max_concurrent = min(\n             task.get(\"max_concurrent\", MAX_CONCURRENT_DOWNLOADS_PER_FOLDER),\n@@ -161,54 +110,54 @@\n                     self.total_active_downloads -= 1\n                 print(f\"Completed download in {folder_name}. Active: {self.active_downloads[folder_name]}\")\n                 print(f\"Total active downloads: {self.total_active_downloads}\")\n \n-            \n-async def process_messages(self, messages):\n-    tasks = []\n-    async with self.lock:\n-        available_slots = self.max_concurrent - self.total_active_downloads\n-        if available_slots > 0:\n-            messages_to_process = messages[:available_slots]\n-            logger.info(f\"Processing {len(messages_to_process)} messages out of {len(messages)} available\")\n-            \n-            # Create coroutines for each task\n-            tasks = [self._process_task(message) for message in messages_to_process]\n-    \n-    if tasks:\n-        # Run tasks concurrently and wait for them to complete\n-        logger.info(f\"Starting {len(tasks)} download tasks\")\n-        await asyncio.gather(*tasks)\n-    else:\n-        logger.info(\"No slots available for downloads, waiting...\")\n-        await asyncio.sleep(1)  \n-            \n-async def run(self):\n-    logger.info(\"Download Manager run starting...\")\n-    try:\n-        messages = []\n-        logger.info(f\"Starting to consume messages from topic: {self._request_topic}\")\n+                \n+    async def process_messages(self, messages):\n+        tasks = []\n+        async with self.lock:\n+            available_slots = self.max_concurrent - self.total_active_downloads\n+            if available_slots > 0:\n+                messages_to_process = messages[:available_slots]\n+                logger.info(f\"Processing {len(messages_to_process)} messages out of {len(messages)} available\")\n+                \n+                # Create coroutines for each task\n+                tasks = [self._process_task(message) for message in messages_to_process]\n         \n-        message_count = 0\n-        async for message in self.message_hub.consume_messages_async(\n-            self._request_topic,\n-            group_id=\"download-manager-group\"\n-        ):\n-            message_count += 1\n-            logger.info(f\"Received message {message_count}: {message}\")\n+        if tasks:\n+            # Run tasks concurrently and wait for them to complete\n+            logger.info(f\"Starting {len(tasks)} download tasks\")\n+            await asyncio.gather(*tasks)\n+        else:\n+            logger.info(\"No slots available for downloads, waiting...\")\n+            await asyncio.sleep(1)  \n+                \n+    async def run(self):\n+        logger.info(\"Download Manager run starting...\")\n+        try:\n+            messages = []\n+            logger.info(f\"Starting to consume messages from topic: {self._request_topic}\")\n             \n-            messages.append(message)\n-            # Process messages more frequently - when we have any messages\n-            if messages:\n-                logger.info(f\"Processing batch of {len(messages)} messages\")\n-                await self.process_messages(messages)\n-                messages = []\n+            message_count = 0\n+            async for message in self.message_hub.consume_messages_async(\n+                self._request_topic,\n+                group_id=\"download-manager-group\"\n+            ):\n+                message_count += 1\n+                logger.info(f\"Received message {message_count}: {message}\")\n                 \n-        logger.info(\"Message consumption completed\")\n-        \n-    except Exception as e:\n-        logger.error(f\"Error in run method: {str(e)}\", exc_info=True)\n-        raise\n+                messages.append(message)\n+                # Process messages more frequently - when we have any messages\n+                if messages:\n+                    logger.info(f\"Processing batch of {len(messages)} messages\")\n+                    await self.process_messages(messages)\n+                    messages = []\n+                    \n+            logger.info(\"Message consumption completed\")\n+            \n+        except Exception as e:\n+            logger.error(f\"Error in run method: {str(e)}\", exc_info=True)\n+            raise\n \n         \n if __name__ == \"__main__\":\n     manager = DownloadManager()\n"
                },
                {
                    "date": 1744765638162,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -55,9 +55,9 @@\n             return f\"SUCCESS: {link} downloaded to {folder_path} as {name}\"\n         else:\n             return f\"FAILED: {link} - {stderr.decode().strip()}\"\n \n-               print(f\"Total active downloads: {self.total_active_downloads}\")\n+     \n \n     async def _process_task(self, task):\n         folder_name = task[\"folder_name\"]\n         max_concurrent = min(\n@@ -110,54 +110,54 @@\n                     self.total_active_downloads -= 1\n                 print(f\"Completed download in {folder_name}. Active: {self.active_downloads[folder_name]}\")\n                 print(f\"Total active downloads: {self.total_active_downloads}\")\n \n-                \n-    async def process_messages(self, messages):\n-        tasks = []\n-        async with self.lock:\n-            available_slots = self.max_concurrent - self.total_active_downloads\n-            if available_slots > 0:\n-                messages_to_process = messages[:available_slots]\n-                logger.info(f\"Processing {len(messages_to_process)} messages out of {len(messages)} available\")\n-                \n-                # Create coroutines for each task\n-                tasks = [self._process_task(message) for message in messages_to_process]\n+            \n+async def process_messages(self, messages):\n+    tasks = []\n+    async with self.lock:\n+        available_slots = self.max_concurrent - self.total_active_downloads\n+        if available_slots > 0:\n+            messages_to_process = messages[:available_slots]\n+            logger.info(f\"Processing {len(messages_to_process)} messages out of {len(messages)} available\")\n+            \n+            # Create coroutines for each task\n+            tasks = [self._process_task(message) for message in messages_to_process]\n+    \n+    if tasks:\n+        # Run tasks concurrently and wait for them to complete\n+        logger.info(f\"Starting {len(tasks)} download tasks\")\n+        await asyncio.gather(*tasks)\n+    else:\n+        logger.info(\"No slots available for downloads, waiting...\")\n+        await asyncio.sleep(1)  \n+            \n+async def run(self):\n+    logger.info(\"Download Manager run starting...\")\n+    try:\n+        messages = []\n+        logger.info(f\"Starting to consume messages from topic: {self._request_topic}\")\n         \n-        if tasks:\n-            # Run tasks concurrently and wait for them to complete\n-            logger.info(f\"Starting {len(tasks)} download tasks\")\n-            await asyncio.gather(*tasks)\n-        else:\n-            logger.info(\"No slots available for downloads, waiting...\")\n-            await asyncio.sleep(1)  \n-                \n-    async def run(self):\n-        logger.info(\"Download Manager run starting...\")\n-        try:\n-            messages = []\n-            logger.info(f\"Starting to consume messages from topic: {self._request_topic}\")\n+        message_count = 0\n+        async for message in self.message_hub.consume_messages_async(\n+            self._request_topic,\n+            group_id=\"download-manager-group\"\n+        ):\n+            message_count += 1\n+            logger.info(f\"Received message {message_count}: {message}\")\n             \n-            message_count = 0\n-            async for message in self.message_hub.consume_messages_async(\n-                self._request_topic,\n-                group_id=\"download-manager-group\"\n-            ):\n-                message_count += 1\n-                logger.info(f\"Received message {message_count}: {message}\")\n+            messages.append(message)\n+            # Process messages more frequently - when we have any messages\n+            if messages:\n+                logger.info(f\"Processing batch of {len(messages)} messages\")\n+                await self.process_messages(messages)\n+                messages = []\n                 \n-                messages.append(message)\n-                # Process messages more frequently - when we have any messages\n-                if messages:\n-                    logger.info(f\"Processing batch of {len(messages)} messages\")\n-                    await self.process_messages(messages)\n-                    messages = []\n-                    \n-            logger.info(\"Message consumption completed\")\n-            \n-        except Exception as e:\n-            logger.error(f\"Error in run method: {str(e)}\", exc_info=True)\n-            raise\n+        logger.info(\"Message consumption completed\")\n+        \n+    except Exception as e:\n+        logger.error(f\"Error in run method: {str(e)}\", exc_info=True)\n+        raise\n \n         \n if __name__ == \"__main__\":\n     manager = DownloadManager()\n"
                },
                {
                    "date": 1744765678585,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -111,53 +111,53 @@\n                 print(f\"Completed download in {folder_name}. Active: {self.active_downloads[folder_name]}\")\n                 print(f\"Total active downloads: {self.total_active_downloads}\")\n \n             \n-async def process_messages(self, messages):\n-    tasks = []\n-    async with self.lock:\n-        available_slots = self.max_concurrent - self.total_active_downloads\n-        if available_slots > 0:\n-            messages_to_process = messages[:available_slots]\n-            logger.info(f\"Processing {len(messages_to_process)} messages out of {len(messages)} available\")\n+    async def process_messages(self, messages):\n+        tasks = []\n+        async with self.lock:\n+            available_slots = self.max_concurrent - self.total_active_downloads\n+            if available_slots > 0:\n+                messages_to_process = messages[:available_slots]\n+                logger.info(f\"Processing {len(messages_to_process)} messages out of {len(messages)} available\")\n+                \n+                # Create coroutines for each task\n+                tasks = [self._process_task(message) for message in messages_to_process]\n+        \n+        if tasks:\n+            # Run tasks concurrently and wait for them to complete\n+            logger.info(f\"Starting {len(tasks)} download tasks\")\n+            await asyncio.gather(*tasks)\n+        else:\n+            logger.info(\"No slots available for downloads, waiting...\")\n+            await asyncio.sleep(1)\n             \n-            # Create coroutines for each task\n-            tasks = [self._process_task(message) for message in messages_to_process]\n-    \n-    if tasks:\n-        # Run tasks concurrently and wait for them to complete\n-        logger.info(f\"Starting {len(tasks)} download tasks\")\n-        await asyncio.gather(*tasks)\n-    else:\n-        logger.info(\"No slots available for downloads, waiting...\")\n-        await asyncio.sleep(1)  \n+    async def run(self):\n+        logger.info(\"Download Manager run starting...\")\n+        try:\n+            messages = []\n+            logger.info(f\"Starting to consume messages from topic: {self._request_topic}\")\n             \n-async def run(self):\n-    logger.info(\"Download Manager run starting...\")\n-    try:\n-        messages = []\n-        logger.info(f\"Starting to consume messages from topic: {self._request_topic}\")\n-        \n-        message_count = 0\n-        async for message in self.message_hub.consume_messages_async(\n-            self._request_topic,\n-            group_id=\"download-manager-group\"\n-        ):\n-            message_count += 1\n-            logger.info(f\"Received message {message_count}: {message}\")\n+            message_count = 0\n+            async for message in self.message_hub.consume_messages_async(\n+                self._request_topic,\n+                group_id=\"download-manager-group\"\n+            ):\n+                message_count += 1\n+                logger.info(f\"Received message {message_count}: {message}\")\n+                \n+                messages.append(message)\n+                # Process messages more frequently - when we have any messages\n+                if messages:\n+                    logger.info(f\"Processing batch of {len(messages)} messages\")\n+                    await self.process_messages(messages)\n+                    messages = []\n+                    \n+            logger.info(\"Message consumption completed\")\n             \n-            messages.append(message)\n-            # Process messages more frequently - when we have any messages\n-            if messages:\n-                logger.info(f\"Processing batch of {len(messages)} messages\")\n-                await self.process_messages(messages)\n-                messages = []\n-                \n-        logger.info(\"Message consumption completed\")\n-        \n-    except Exception as e:\n-        logger.error(f\"Error in run method: {str(e)}\", exc_info=True)\n-        raise\n+        except Exception as e:\n+            logger.error(f\"Error in run method: {str(e)}\", exc_info=True)\n+            raise\n \n         \n if __name__ == \"__main__\":\n     manager = DownloadManager()\n"
                },
                {
                    "date": 1744766040319,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -133,32 +133,32 @@\n             \n     async def run(self):\n         logger.info(\"Download Manager run starting...\")\n         try:\n-            messages = []\n+            messages_buffer = []\n+            batch_size = self.max_concurrent\n             logger.info(f\"Starting to consume messages from topic: {self._request_topic}\")\n             \n-            message_count = 0\n             async for message in self.message_hub.consume_messages_async(\n                 self._request_topic,\n                 group_id=\"download-manager-group\"\n             ):\n-                message_count += 1\n-                logger.info(f\"Received message {message_count}: {message}\")\n+                messages_buffer.append(message)\n                 \n-                messages.append(message)\n-                # Process messages more frequently - when we have any messages\n-                if messages:\n-                    logger.info(f\"Processing batch of {len(messages)} messages\")\n-                    await self.process_messages(messages)\n-                    messages = []\n+                # Process when we have enough messages for a batch\n+                if len(messages_buffer) >= batch_size:\n+                    logger.info(f\"Processing batch of {len(messages_buffer)} messages\")\n+                    await self.process_messages(messages_buffer)\n+                    messages_buffer = []  # Clear the buffer after processing\n                     \n-            logger.info(\"Message consumption completed\")\n-            \n+            # Process any remaining messages\n+            if messages_buffer:\n+                logger.info(f\"Processing final batch of {len(messages_buffer)} messages\")\n+                await self.process_messages(messages_buffer)\n+                \n         except Exception as e:\n             logger.error(f\"Error in run method: {str(e)}\", exc_info=True)\n             raise\n-\n         \n if __name__ == \"__main__\":\n     manager = DownloadManager()\n     asyncio.run(manager.run())\n\\ No newline at end of file\n"
                },
                {
                    "date": 1744766064345,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -113,24 +113,26 @@\n \n             \n     async def process_messages(self, messages):\n         tasks = []\n-        async with self.lock:\n-            available_slots = self.max_concurrent - self.total_active_downloads\n-            if available_slots > 0:\n-                messages_to_process = messages[:available_slots]\n-                logger.info(f\"Processing {len(messages_to_process)} messages out of {len(messages)} available\")\n-                \n-                # Create coroutines for each task\n-                tasks = [self._process_task(message) for message in messages_to_process]\n+        folder_counts = defaultdict(int)\n         \n+        # Group messages by folder and respect folder limits\n+        for message in messages:\n+            folder_name = message[\"folder_name\"]\n+            folder_limit = message.get(\"max_concurrent\", MAX_CONCURRENT_DOWNLOADS_PER_FOLDER)\n+            \n+            if (folder_counts[folder_name] < folder_limit and \n+                len(tasks) < self.max_concurrent):\n+                tasks.append(self._process_task(message))\n+                folder_counts[folder_name] += 1\n+        \n         if tasks:\n-            # Run tasks concurrently and wait for them to complete\n-            logger.info(f\"Starting {len(tasks)} download tasks\")\n+            logger.info(f\"Starting {len(tasks)} concurrent downloads\")\n             await asyncio.gather(*tasks)\n         else:\n             logger.info(\"No slots available for downloads, waiting...\")\n-            await asyncio.sleep(1)\n+            await asyncio.sleep(1)   \n             \n     async def run(self):\n         logger.info(\"Download Manager run starting...\")\n         try:\n"
                },
                {
                    "date": 1744766480151,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -132,35 +132,46 @@\n         else:\n             logger.info(\"No slots available for downloads, waiting...\")\n             await asyncio.sleep(1)   \n             \n+\n     async def run(self):\n         logger.info(\"Download Manager run starting...\")\n         try:\n             messages_buffer = []\n             batch_size = self.max_concurrent\n-            logger.info(f\"Starting to consume messages from topic: {self._request_topic}\")\n+            logger.info(f\"Starting to consume messages from topic: {self._request_topic} with batch size {batch_size}\")\n             \n             async for message in self.message_hub.consume_messages_async(\n                 self._request_topic,\n                 group_id=\"download-manager-group\"\n             ):\n                 messages_buffer.append(message)\n+                logger.info(f\"Received message. Buffer size: {len(messages_buffer)}\")\n                 \n-                # Process when we have enough messages for a batch\n+                # Process immediately if we have enough messages or after a short timeout\n                 if len(messages_buffer) >= batch_size:\n-                    logger.info(f\"Processing batch of {len(messages_buffer)} messages\")\n+                    logger.info(f\"Processing full batch of {len(messages_buffer)} messages\")\n                     await self.process_messages(messages_buffer)\n-                    messages_buffer = []  # Clear the buffer after processing\n-                    \n+                    messages_buffer = []\n+                elif messages_buffer:  # Process partial batch after a short delay\n+                    logger.info(f\"Processing partial batch of {len(messages_buffer)} messages\")\n+                    await self.process_messages(messages_buffer)\n+                    messages_buffer = []\n+                \n+                # Small delay to allow more messages to accumulate\n+                await asyncio.sleep(0.1)\n+                \n             # Process any remaining messages\n             if messages_buffer:\n                 logger.info(f\"Processing final batch of {len(messages_buffer)} messages\")\n                 await self.process_messages(messages_buffer)\n-                \n+                    \n         except Exception as e:\n             logger.error(f\"Error in run method: {str(e)}\", exc_info=True)\n             raise\n-        \n+\n+\n+\n if __name__ == \"__main__\":\n     manager = DownloadManager()\n     asyncio.run(manager.run())\n\\ No newline at end of file\n"
                },
                {
                    "date": 1744766629348,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -132,9 +132,8 @@\n         else:\n             logger.info(\"No slots available for downloads, waiting...\")\n             await asyncio.sleep(1)   \n             \n-\n     async def run(self):\n         logger.info(\"Download Manager run starting...\")\n         try:\n             messages_buffer = []\n@@ -147,26 +146,21 @@\n             ):\n                 messages_buffer.append(message)\n                 logger.info(f\"Received message. Buffer size: {len(messages_buffer)}\")\n                 \n-                # Process immediately if we have enough messages or after a short timeout\n+                # Only process when we have a full batch\n                 if len(messages_buffer) >= batch_size:\n                     logger.info(f\"Processing full batch of {len(messages_buffer)} messages\")\n                     await self.process_messages(messages_buffer)\n                     messages_buffer = []\n-                elif messages_buffer:  # Process partial batch after a short delay\n-                    logger.info(f\"Processing partial batch of {len(messages_buffer)} messages\")\n-                    await self.process_messages(messages_buffer)\n-                    messages_buffer = []\n+                    \n+                # Don't process partial batches immediately - removed the elif block\n                 \n-                # Small delay to allow more messages to accumulate\n-                await asyncio.sleep(0.1)\n-                \n-            # Process any remaining messages\n+            # Process any remaining messages at the end\n             if messages_buffer:\n                 logger.info(f\"Processing final batch of {len(messages_buffer)} messages\")\n                 await self.process_messages(messages_buffer)\n-                    \n+                        \n         except Exception as e:\n             logger.error(f\"Error in run method: {str(e)}\", exc_info=True)\n             raise\n \n"
                }
            ],
            "date": 1744751360376,
            "name": "Commit-0",
            "content": "from cookies_authentication import (\n    create_cookies_from_browser_cookies,\n    save_cookies_to_file,\n)\nfrom message_hub import MessageHub\nimport asyncio\nimport os\n\n\nasync def download_video(cookies_path, link, name, folder_path):\n    \"\"\"\n    Asynchronously download a video using yt-dlp.\n    \"\"\"\n    os.makedirs(folder_path, exist_ok=True)\n    output_path = os.path.join(folder_path, f\"{name}.%(ext)s\")\n    if cookies_path is None:\n        command = [\n            \"yt-dlp\",\n            link,\n            \"-o\",\n            os.path.abspath(output_path),\n        ]\n    else:\n        command = [\n            \"yt-dlp\",\n            \"--cookies\",\n            os.path.abspath(cookies_path),\n            link,\n            \"-o\",\n            os.path.abspath(output_path),\n        ]\n\n    process = await asyncio.create_subprocess_exec(\n        *command,\n        stdout=asyncio.subprocess.PIPE,        stderr=asyncio.subprocess.PIPE,\n    )\n    stdout, stderr = await process.communicate()\n\n    if process.returncode == 0:\n        return f\"SUCCESS: {link} downloaded to {folder_path} as {name}\"\n    else:\n        return f\"FAILED: {link} - {stderr.decode().strip()}\"\n\n\nasync def process_task(task,  message_hub, status_topic):\n    \"\"\"\n    Processes a single download task.\n    \"\"\"\n    try:\n        link = task[\"link\"]\n        name = task[\"name\"]\n        try: \n            need_cookies = task[\"need_authentication\"] \n        except KeyError:\n            need_cookies = False\n            cookies_path = None\n            \n        \n        cookies_path = None\n        folder_name = task[\"folder_name\"]\n        folder_path = os.path.join(\"./resources\", folder_name)\n        if eval(need_cookies):\n            raw_cookie_path = task[\"raw_cookies_path\"]\n            cookies_path =  task[\"cookies_path\"]\n            cookies = create_cookies_from_browser_cookies(raw_cookie_path)\n            save_cookies_to_file(cookies_path, cookies)   \n            \n\n        # Execute the download\n        status = await download_video(cookies_path, link, name, folder_path)\n\n        # Publish the status to the status topic\n        message_hub.send_message(status_topic, key=name, value={\"status\": status})\n    except Exception as e:\n        error_message = f\"Error processing task: {str(e)}\"\n        print(error_message)\n        message_hub.send_message(status_topic, key=name, value={\"status\": error_message})\n\n"
        }
    ]
}